{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in die Neuroinformatik - 7. Aufgabenblatt\n",
    "## Gruppe Q: Dominik Authaler, Marco Deuscher, Carolin Schindler\n",
    "\n",
    "### Aufgabe 1: Learning Slowdown\n",
    "\n",
    "#### 1. Untersuchung von $\\frac{\\partial E}{\\partial b_2}$\n",
    "##### a) $\\frac{\\partial E}{\\partial b_2}$ mit gegebenen Werten berechnen\n",
    "$\\frac{\\partial E}{\\partial b_2} = 2 \\cdot f(1,5) \\cdot f(1,5) \\cdot (1-f(1,5)) \\approx 0,24$\n",
    "##### b) $\\frac{\\partial E}{\\partial b_2}$ mit neuen Werten berechnen\n",
    "$\\frac{\\partial E}{\\partial b_2} = 2 \\cdot f(4) \\cdot f(4) \\cdot (1-f(4)) \\approx 0,0347$\n",
    "##### c) Welches Problem haben wir im letzten Fall und welcher Faktor ist dafür hauptsächlich verantwortlich?\n",
    "Problem: Gradient sehr klein. D.h. Netzwerk lernt sehr langsam, es dauert also lange bis die Netzwerkausgabe dem Lehrersignal entspricht.  \n",
    "verantwortlicher Faktor: $f'(u_2)$ mit großem $u_2$\n",
    "\n",
    "#### 2. zwei lernende Neuronen\n",
    "##### a) $\\frac{\\partial E}{\\partial b_1}$ berechnen und argumentieren, ob das obige Problem verstärkt oder abgeschwächt wird\n",
    "$\\frac{\\partial E}{\\partial b_1} = -2\\cdot (T-y_2)\\cdot f'(u_2)\\cdot w_2\\cdot f'(u_1)$  \n",
    "Das Probelm wird verstärkt, da nun $f'(u_i)$ zweimal vorkommt und somit quasi quadratisch eingeht.\n",
    "##### b) Wie würde sich das Problem bei noch mehr Zwischenschichten weiterentwickeln?\n",
    "Das Problem würde sich mit jeder weiteren Zwischenschicht verstärken, da mit jeder Schicht in der Ableitung der Fehlerfunktion ein weiterer Faktor $f'(u_i)$ hinzukommt.\n",
    "##### c) Warum kann sich dadurch die Suche nach einem lokalen Minimum in die Länge ziehen?\n",
    "Lernvorgang geht sehr langsam voran bis $u_i$ kleiner werden. Je größer also die $u_i$ zu Beginn gewählt wurden, desto länger dauert es bis die Ausgabe dem Lehrersignal entspricht.\n",
    "\n",
    "#### 3. Untersuchung eines weiteren Problems\n",
    "##### a) $\\frac{\\partial E}{\\partial b_2}$ und $\\frac{\\partial E}{\\partial b_1}$ mit gegebenen Werten berechnen\n",
    "$\\frac{\\partial E}{\\partial b_2} = 2 \\cdot f(0) \\cdot f(0) \\cdot (1-f(0)) = 0,25 $  \n",
    "$\\frac{\\partial E}{\\partial b_1} = 2\\cdot f(0) \\cdot [f(0) \\cdot (1-f(0))]^2 \\cdot 100 = 6,25 $\n",
    "##### b) Wie entwickelt sich die begonnene Folge für noch mehr Zwischenschichten?\n",
    "$\\frac{\\partial E}{\\partial b_n} = 2\\cdot f(0) \\cdot [f(0) \\cdot (1-f(0))]^n \\cdot 100^{n-1} = (0,25)^n \\cdot 100^{n-1} = \\frac{(25)^n}{100} \\rightarrow \\infty \\text{ für } n \\rightarrow \\infty$  \n",
    "mit $n \\geq 1$ Schichtnummer von Ausgang ($n=1$) zu Eingang ($n \\rightarrow \\infty$)\n",
    "##### c) Was für ein Problem können wir nun beobachten? Warum kann dies die Suche nach einem lokalen Minimum ebenfalls erschweren?\n",
    "Problem: Gradient sehr groß. D.h. Netzwerk lernt sehr schnell, es kann also passieren, dass lokale Minima (ständig) übersprungen werden.\n",
    "\n",
    "#### 4. Inwieweit löst die cross entropy-Funktion zumindest zum Teil das hier beschriebene Problem?\n",
    "$f'(u_i)$ kommt im Gradienten der cross entropy-Funktion einmal weniger vor als im Gradienten der qaudratischen Fehlerunktion. Dadurch treten die obigen Probleme weniger stark auf.\n",
    "\n",
    "\n",
    "### Aufgabe 2: Flat vs. Deep Networks\n",
    "\n",
    "#### 1. Untersuchung der Lösung $net_d$\n",
    "##### a) Netzwerkausgabe für gegebene Eingabe berechnen und überprüfen\n",
    "$f(x,y) = 0$  \n",
    "$f((0,0), (1,1)) =(\\sum_{i=1}^2 x_i\\cdot y_i)\\mod 2 = (0\\cdot 1 + 0\\cdot 1)\\mod 2 = 0\\mod 2 = 0$\n",
    "##### b) Netzwerk für $n=3$ erweitern\n",
    "Pfeile ohne Zahl sind mit $1$ gewichtet\n",
    "<img src=\"Blatt07_Bild21b.png\"> \n",
    "##### c) Welche Rolle kommt den Neuronen in der 1. und 2. Zwischenschicht jeweils zu? Welche Art Zwischenergebnis berechnen sie?\n",
    "Neuronen in der 1. Zwischenschicht berechenen jeweils für ein festes $i$: $x_i \\cdot y_i$.  \n",
    "Neuronen in der 2. Zwischenschicht berechnen die Anzahl an Neuronen in der 1. Zwischenschicht, die eine $1$ ausgegeben haben.\n",
    "\n",
    "#### 2. Überprüfung der Gleichung für die Anzahl an benötigten Neuronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Interpretiere die Ergenisse für höhere Eingabedimensionen\n",
    "XXX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
